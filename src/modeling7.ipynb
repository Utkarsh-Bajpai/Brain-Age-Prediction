{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import r2_score\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.linear_model import Ridge, ElasticNet, BayesianRidge\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update your data path\n",
    "DATA_PATH = \"/home/aunagar/Personal/Study/Sem1/Advanced ML/projects/task1/Task1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "train_X = pd.read_csv(DATA_PATH + \"X_train.csv\")\n",
    "train_Y = pd.read_csv(DATA_PATH + \"y_train.csv\")\n",
    "test_X = pd.read_csv(DATA_PATH + \"X_test.csv\")\n",
    "sample_submission = pd.read_csv(DATA_PATH + \"sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train_ids = train_X.iloc[:, 0]\n",
    "train_features = train_X.iloc[:, 1:]\n",
    "test_ids = test_X.iloc[:, 0]\n",
    "test_features = test_X.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## missing value imputation (median) ########\n",
    "# train\n",
    "train_features = train_features.fillna(train_features.mean())\n",
    "# test\n",
    "test_features = test_features.fillna(train_features.mean())\n",
    "\n",
    "\n",
    "####### limiting feature using variance threshold (i.e. remove features with 0 variance) ######\n",
    "train_features_mean, train_features_std = train_features.mean(), train_features.std()\n",
    "\n",
    "train_features = train_features.iloc[:, np.where(train_features_std > 0.0)[0]]\n",
    "test_features = test_features.iloc[:, np.where(train_features_std > 0.0)[0]]\n",
    "\n",
    "############## Outlier removal ###############\n",
    "train_features_mean, train_features_std = train_features.mean(), train_features.std()\n",
    "# train\n",
    "train_features[train_features > train_features_mean + 2.*train_features_std] = np.nan\n",
    "train_features[train_features < train_features_mean -2.*train_features_std] = np.nan\n",
    "train_features = train_features.fillna(train_features.mean())\n",
    "\n",
    "# test\n",
    "test_features[test_features > train_features_mean + 2.*train_features_std] = np.nan\n",
    "test_features[test_features < train_features_mean - 2.*train_features_std] = np.nan\n",
    "test_features = test_features.fillna(train_features.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Normalization #####\n",
    "# train\n",
    "train_mean, train_std = train_features.mean(), train_features.std()\n",
    "train_features = (train_features - train_mean)/train_std\n",
    "# test \n",
    "test_features = (test_features - train_mean)/train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Correlated feature removal #########\n",
    "# Create correlation matrix\n",
    "corr_matrix = train_features.corr().abs()\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "# Find index of feature columns with correlation greater than 0.7\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\n",
    "\n",
    "# # train\n",
    "# train_features = train_features.drop(columns = to_drop)\n",
    "# # test\n",
    "# test_features = test_features.drop(columns = to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha = np.arange(0.1, 2., 0.4)\n",
    "l1_ratio = np.arange(0.1,1.,0.4)\n",
    "results = pd.DataFrame(columns=['alpha', 'l1_ratio', 'cv_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 ,  0.1 ,  0.46467041322348057 \n",
      "\n",
      "Rfr validation score:  0.4856688936687591 \n",
      "\n",
      "0.1 ,  0.5 ,  0.46410770011941815 \n",
      "\n",
      "Rfr validation score:  0.4852579943996792 \n",
      "\n",
      "0.1 ,  0.9 ,  0.4636486085630616 \n",
      "\n",
      "Rfr validation score:  0.4843836982398395 \n",
      "\n",
      "0.5 ,  0.1 ,  0.46449754018927586 \n",
      "\n",
      "Rfr validation score:  0.485459171063605 \n",
      "\n",
      "0.5 ,  0.5 ,  0.4620328366779666 \n",
      "\n",
      "Rfr validation score:  0.48612076706730767 \n",
      "\n",
      "0.5 ,  0.9 ,  0.4580077189508291 \n",
      "\n",
      "Rfr validation score:  0.48624439605699166 \n",
      "\n",
      "0.9 ,  0.1 ,  0.4596991601066714 \n",
      "\n",
      "Rfr validation score:  0.48676272348825345 \n",
      "\n",
      "0.9 ,  0.5 ,  0.4538195087384194 \n",
      "\n",
      "Rfr validation score:  0.48330467003672295 \n",
      "\n",
      "0.9 ,  0.9 ,  0.443850293027659 \n",
      "\n",
      "Rfr validation score:  0.4869515021759798 \n",
      "\n",
      "1.3000000000000003 ,  0.1 ,  0.4526003150049108 \n",
      "\n",
      "Rfr validation score:  0.48629305200567535 \n",
      "\n",
      "1.3000000000000003 ,  0.5 ,  0.4413911678543515 \n",
      "\n",
      "Rfr validation score:  0.4866178286937153 \n",
      "\n",
      "1.3000000000000003 ,  0.9 ,  0.42162898096640894 \n",
      "\n",
      "Rfr validation score:  0.48664288066782735 \n",
      "\n",
      "1.7000000000000002 ,  0.1 ,  0.44404309968578304 \n",
      "\n",
      "Rfr validation score:  0.48546102236796196 \n",
      "\n",
      "1.7000000000000002 ,  0.5 ,  0.4257339501604517 \n",
      "\n",
      "Rfr validation score:  0.48717001093274936 \n",
      "\n",
      "1.7000000000000002 ,  0.9 ,  0.39294533943809407 \n",
      "\n",
      "Rfr validation score:  0.48639645484330585 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "###### linear model\n",
    "for a in alpha:\n",
    "    for l1 in l1_ratio:\n",
    "        lr = ElasticNet(alpha = a, l1_ratio=l1)\n",
    "        validation_score = cross_val_score(lr, train_features, train_Y.iloc[:, 1:], cv = 5, scoring = 'r2')\n",
    "        print(a, \", \", l1, \", \", validation_score.mean(), \"\\n\")\n",
    "\n",
    "        # train model on whole train data\n",
    "        lr.fit(X = train_features, y = train_Y.iloc[:, 1])\n",
    "        # finding to which features to remove\n",
    "        non_zero_weights = np.where(lr.coef_ != 0.)[0]\n",
    "\n",
    "        # removing these features from training data\n",
    "        train_features = train_features.iloc[:, non_zero_weights]\n",
    "        test_features = test_features.iloc[:, non_zero_weights]\n",
    "        \n",
    "        #### training more complex model on this cleared data\n",
    "        rfr = RandomForestRegressor(n_estimators=500, max_depth=5, verbose = False, n_jobs = -1)\n",
    "        validation_score = cross_val_score(rfr, train_features, train_Y.iloc[:, 1], cv = 5, scoring= 'r2')\n",
    "        print(\"Rfr validation score: \", validation_score.mean(), \"\\n\")\n",
    "        results = results.append({'alpha':a, 'l1_ratio':l1, 'cv_score':validation_score.mean()}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding to which features to remove\n",
    "non_zero_weights = np.where(lr.coef_ != 0.)[0]\n",
    "\n",
    "# removing these features from training data\n",
    "train_features = train_features.iloc[:, non_zero_weights]\n",
    "test_features = test_features.iloc[:, non_zero_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aunagar/miniconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:17:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aunagar/miniconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:17:50] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aunagar/miniconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:17:55] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aunagar/miniconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:18:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aunagar/miniconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:18:07] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "0.41871526873359244\n"
     ]
    }
   ],
   "source": [
    "xgbr = xgb.XGBRegressor(learning_rate=0.4, max_depth=5, n_estimators=500)\n",
    "validation_score = cross_val_score(xgbr, train_features, train_Y.iloc[:, 1], cv = 5, scoring = 'r2')\n",
    "print(validation_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = best_model.predict(test_features)\n",
    "sample_submission['y'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submissions/Ajay_4th_sub.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
